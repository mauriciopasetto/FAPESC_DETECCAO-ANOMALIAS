{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae56b0dc",
   "metadata": {},
   "source": [
    "# PPD dos dados para treinamento, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c502ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##importando bibliotecas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "from numpy import median, mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50658c9f",
   "metadata": {},
   "source": [
    "* Outlier =  1 normal\n",
    "* Outlier = -1 anormal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4cec46",
   "metadata": {},
   "source": [
    "## GERAL - DIA - importando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367e5e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 9)\n",
      "(84, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dia</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>fim_semana</th>\n",
       "      <th>cclothes</th>\n",
       "      <th>eating</th>\n",
       "      <th>mcoffe</th>\n",
       "      <th>mhotfood</th>\n",
       "      <th>toileting</th>\n",
       "      <th>whandface</th>\n",
       "      <th>var_cclothes</th>\n",
       "      <th>var_eating</th>\n",
       "      <th>var_mcoffe</th>\n",
       "      <th>var_mhotfood</th>\n",
       "      <th>var_toileting</th>\n",
       "      <th>var_whandface</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>562.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1332.00</td>\n",
       "      <td>274.454545</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>405.500000</td>\n",
       "      <td>2538.000000</td>\n",
       "      <td>356.333333</td>\n",
       "      <td>2420.5</td>\n",
       "      <td>684.00</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>386.666667</td>\n",
       "      <td>2547.333333</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>480.25</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>4938.000000</td>\n",
       "      <td>745.000000</td>\n",
       "      <td>963.0</td>\n",
       "      <td>793.00</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>1035.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>2896.0</td>\n",
       "      <td>149.00</td>\n",
       "      <td>262.125000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dia  dia_semana  fim_semana    cclothes       eating      mcoffe  mhotfood  \\\n",
       "0    1           0           0  562.000000  1359.000000  232.000000    1191.0   \n",
       "1    2           1           0  405.500000  2538.000000  356.333333    2420.5   \n",
       "2    3           2           0  386.666667  2547.333333  291.000000    2923.0   \n",
       "3    4           3           0  438.000000  4938.000000  745.000000     963.0   \n",
       "4    5           4           0  190.000000  1035.000000  302.000000    2896.0   \n",
       "\n",
       "   toileting   whandface  var_cclothes  var_eating  var_mcoffe  var_mhotfood  \\\n",
       "0    1332.00  274.454545             1          -1          -1            -1   \n",
       "1     684.00  520.000000             1           1           1             1   \n",
       "2     480.25  139.000000             1           1          -1             1   \n",
       "3     793.00  140.000000             1          -1          -1            -1   \n",
       "4     149.00  262.125000            -1          -1          -1             1   \n",
       "\n",
       "   var_toileting  var_whandface  outlier  \n",
       "0             -1              1       -1  \n",
       "1             -1             -1       -1  \n",
       "2              1             -1       -1  \n",
       "3             -1             -1       -1  \n",
       "4             -1              1       -1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Atributo DFREQ\n",
    "## importando dataset TREINAMENTO\n",
    "df_dfreq_trein = pd.read_csv('dataseteh/pp4/eh-dfreq-trein.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "dia_trein = df_dfreq_trein.iloc[0:14].copy()\n",
    "print(dia_trein.shape)\n",
    "## importando dataset de TESTE\n",
    "df_dfreq_test = pd.read_csv('dataseteh/pp4/eh-dfreq-test84.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "dia_teste = df_dfreq_test.copy()\n",
    "print(dia_teste.shape)\n",
    "dia_teste.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c140561f",
   "metadata": {},
   "source": [
    "## ATIVIDADES INDIV - DIA - importando dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00feb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 7)\n",
      "(84, 7)\n",
      "(14, 7)\n",
      "(84, 7)\n",
      "(14, 7)\n",
      "(84, 7)\n",
      "(14, 7)\n",
      "(84, 7)\n",
      "(14, 7)\n",
      "(84, 7)\n",
      "(14, 7)\n",
      "(84, 7)\n"
     ]
    }
   ],
   "source": [
    "#1 cclothes\n",
    "## importando dataset TREINAMENTO\n",
    "df_cclothes_trein = pd.read_csv('dataseteh/pp4/eh-ativ-cclothes-treinfull.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "df_cclothes_trein = df_cclothes_trein.iloc[0:14].copy()\n",
    "print(df_cclothes_trein.shape)\n",
    "## importando dataset de TESTE\n",
    "df_cclothes_teste = pd.read_csv('dataseteh/pp4/eh-ativ-cclothes-test84.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "print(df_cclothes_teste.shape)\n",
    "\n",
    "#2 eating\n",
    "## importando dataset TREINAMENTO\n",
    "df_eating_trein = pd.read_csv('dataseteh/pp4/eh-ativ-eating-treinfull.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "df_eating_trein = df_eating_trein.iloc[0:14].copy()\n",
    "print(df_eating_trein.shape)\n",
    "## importando dataset de TESTE\n",
    "df_eating_teste = pd.read_csv('dataseteh/pp4/eh-ativ-eating-test84.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "print(df_eating_teste.shape)\n",
    "\n",
    "#3 mcoffe\n",
    "## importando dataset TREINAMENTO\n",
    "df_mcoffe_trein = pd.read_csv('dataseteh/pp4/eh-ativ-mcoffe-treinfull.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "df_mcoffe_trein = df_mcoffe_trein.iloc[0:14].copy()\n",
    "print(df_mcoffe_trein.shape)\n",
    "## importando dataset de TESTE\n",
    "df_mcoffe_teste = pd.read_csv('dataseteh/pp4/eh-ativ-mcoffe-test84.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "print(df_mcoffe_teste.shape)\n",
    "\n",
    "#4 mhotfood\n",
    "## importando dataset TREINAMENTO\n",
    "df_mhotfood_trein = pd.read_csv('dataseteh/pp4/eh-ativ-mhotfood-treinfull.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "df_mhotfood_trein = df_mhotfood_trein.iloc[0:14].copy()\n",
    "print(df_mhotfood_trein.shape)\n",
    "## importando dataset de TESTE\n",
    "df_mhotfood_teste = pd.read_csv('dataseteh/pp4/eh-ativ-mhotfood-test84.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "print(df_mhotfood_teste.shape)\n",
    "\n",
    "#5 toileting\n",
    "## importando dataset TREINAMENTO\n",
    "df_toileting_trein = pd.read_csv('dataseteh/pp4/eh-ativ-toileting-treinfull.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "df_toileting_trein = df_toileting_trein.iloc[0:14].copy()\n",
    "print(df_toileting_trein.shape)\n",
    "## importando dataset de TESTE\n",
    "df_toileting_teste = pd.read_csv('dataseteh/pp4/eh-ativ-toileting-test84.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "print(df_toileting_teste.shape)\n",
    "\n",
    "#6 whandface\n",
    "## importando dataset TREINAMENTO\n",
    "df_whandface_trein = pd.read_csv('dataseteh/pp4/eh-ativ-whandface-treinfull.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "df_whandface_trein = df_whandface_trein.iloc[0:14].copy()\n",
    "print(df_whandface_trein.shape)\n",
    "## importando dataset de TESTE\n",
    "df_whandface_teste = pd.read_csv('dataseteh/pp4/eh-ativ-whandface-test84.csv',delimiter=';',decimal=',',thousands=\".\",encoding='ANSI')\n",
    "print(df_whandface_teste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f19ee",
   "metadata": {},
   "source": [
    "## TREINAMENTO MODELO GERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea897d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocalOutlierFactor(n_neighbors=10, novelty=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecao dos dados\n",
    "dia_trein_s = dia_trein.iloc[:, [1,2,3,4,5,6,7,8]].copy()\n",
    "dia_teste_s = dia_teste.iloc[:, [1,2,3,4,5,6,7,8]].copy()\n",
    "\n",
    "#standarização\n",
    "scaler = StandardScaler().fit(dia_trein_s)\n",
    "dia_trein_s = scaler.transform(dia_trein_s).copy()\n",
    "dia_teste_s = scaler.transform(dia_teste_s).copy()\n",
    "\n",
    "#treinamento\n",
    "lof_dia = LocalOutlierFactor(n_neighbors=10, novelty=True)\n",
    "lof_dia.fit(dia_trein_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d245720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EllipticEnvelope(contamination=0.01, random_state=1, support_fraction=0.9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cclothes\n",
    "#selecao dos dados\n",
    "cclothes_trein_s = df_cclothes_trein.iloc[:, [1,2,3,4,5]].copy()\n",
    "cclothes_teste_s = df_cclothes_teste.iloc[:, [1,2,3,4,5]].copy()\n",
    "\n",
    "#standarização\n",
    "scaler = StandardScaler().fit(cclothes_trein_s)\n",
    "cclothes_trein_s = scaler.transform(cclothes_trein_s).copy()\n",
    "cclothes_teste_s = scaler.transform(cclothes_teste_s).copy()\n",
    "\n",
    "#treinamento\n",
    "rce_cclothes = EllipticEnvelope(contamination= 0.01, random_state=1, support_fraction= 0.9)\n",
    "rce_cclothes.fit(cclothes_trein_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "685c15e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EllipticEnvelope(contamination=0.01, random_state=1, support_fraction=0.9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eating\n",
    "#selecao dos dados\n",
    "eating_trein_s = df_eating_trein.iloc[:, [1,2,3,4,5]].copy()\n",
    "eating_teste_s = df_eating_teste.iloc[:, [1,2,3,4,5]].copy()\n",
    "\n",
    "#standarização\n",
    "scaler = StandardScaler().fit(eating_trein_s)\n",
    "eating_trein_s = scaler.transform(eating_trein_s).copy()\n",
    "eating_teste_s = scaler.transform(eating_teste_s).copy()\n",
    "\n",
    "#treinamento\n",
    "rce_eating = EllipticEnvelope(contamination= 0.01, random_state=1, support_fraction= 0.9)\n",
    "rce_eating.fit(eating_trein_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2724589e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EllipticEnvelope(contamination=0.01, random_state=1, support_fraction=0.9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mcoffe\n",
    "#selecao dos dados\n",
    "mcoffe_trein_s = df_mcoffe_trein.iloc[:, [1,2,3,4,5]].copy()\n",
    "mcoffe_teste_s = df_mcoffe_teste.iloc[:, [1,2,3,4,5]].copy()\n",
    "\n",
    "#standarização\n",
    "scaler = StandardScaler().fit(mcoffe_trein_s)\n",
    "mcoffe_trein_s = scaler.transform(mcoffe_trein_s).copy()\n",
    "mcoffe_teste_s = scaler.transform(mcoffe_teste_s).copy()\n",
    "\n",
    "#treinamento\n",
    "rce_mcoffe = EllipticEnvelope(contamination= 0.01, random_state=1, support_fraction= 0.9)\n",
    "rce_mcoffe.fit(mcoffe_trein_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcb57765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EllipticEnvelope(contamination=0.01, random_state=1, support_fraction=0.9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mhotfood\n",
    "#selecao dos dados\n",
    "mhotfood_trein_s = df_mhotfood_trein.iloc[:, [1,2,3,4,5]].copy()\n",
    "mhotfood_teste_s = df_mhotfood_teste.iloc[:, [1,2,3,4,5]].copy()\n",
    "\n",
    "#standarização\n",
    "scaler = StandardScaler().fit(mhotfood_trein_s)\n",
    "mhotfood_trein_s = scaler.transform(mhotfood_trein_s).copy()\n",
    "mhotfood_teste_s = scaler.transform(mhotfood_teste_s).copy()\n",
    "\n",
    "#treinamento\n",
    "rce_mhotfood = EllipticEnvelope(contamination= 0.01, random_state=1, support_fraction= 0.9)\n",
    "rce_mhotfood.fit(mhotfood_trein_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d680c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EllipticEnvelope(contamination=0.01, random_state=1, support_fraction=0.9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#toileting\n",
    "#selecao dos dados\n",
    "toileting_trein_s = df_toileting_trein.iloc[:, [1,2,3,4,5]].copy()\n",
    "toileting_teste_s = df_toileting_teste.iloc[:, [1,2,3,4,5]].copy()\n",
    "\n",
    "#standarização\n",
    "scaler = StandardScaler().fit(toileting_trein_s)\n",
    "toileting_trein_s = scaler.transform(toileting_trein_s).copy()\n",
    "toileting_teste_s = scaler.transform(toileting_teste_s).copy()\n",
    "\n",
    "#treinamento\n",
    "rce_toileting = EllipticEnvelope(contamination= 0.01, random_state=1, support_fraction= 0.9)\n",
    "rce_toileting.fit(toileting_trein_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dfd2b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EllipticEnvelope(contamination=0.01, random_state=1, support_fraction=0.9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#whandface\n",
    "#selecao dos dados\n",
    "whandface_trein_s = df_whandface_trein.iloc[:, [1,2,3,4,5]].copy()\n",
    "whandface_teste_s = df_whandface_teste.iloc[:, [1,2,3,4,5]].copy()\n",
    "\n",
    "#standarização\n",
    "scaler = StandardScaler().fit(whandface_trein_s)\n",
    "whandface_trein_s = scaler.transform(whandface_trein_s).copy()\n",
    "whandface_teste_s = scaler.transform(whandface_teste_s).copy()\n",
    "\n",
    "#treinamento\n",
    "rce_whandface = EllipticEnvelope(contamination= 0.01, random_state=1, support_fraction= 0.9)\n",
    "rce_whandface.fit(whandface_trein_s)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1fbb46fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef8c9ea4",
   "metadata": {},
   "source": [
    "## Detecção de anomalias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ecbebdf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dia  1  anormal\n",
      "[1, 'eating', 'mhotfood', 'toileting']\n",
      "Dia  2  anormal\n",
      "[2, 'toileting', 'whandface']\n",
      "Dia  3  anormal\n",
      "[3, 'whandface']\n",
      "Dia  4  anormal\n",
      "[4, 'eating', 'mcoffe', 'mhotfood', 'whandface']\n",
      "Dia  5  anormal\n",
      "[5, 'cclothes', 'eating']\n",
      "Dia  6  anormal\n",
      "[6, 'cclothes', 'eating', 'toileting']\n",
      "Dia  7  anormal\n",
      "[7, 'cclothes', 'mhotfood']\n",
      "Dia  8  anormal\n",
      "[8, 'cclothes', 'eating', 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  9  anormal\n",
      "[9, 'eating', 'mcoffe', 'toileting']\n",
      "Dia  10  anormal\n",
      "[10, 'cclothes', 'mhotfood', 'toileting']\n",
      "Dia  11  anormal\n",
      "[11, 'eating', 'mhotfood']\n",
      "Dia  12  anormal\n",
      "[12, 'cclothes', 'eating', 'mhotfood', 'whandface']\n",
      "Dia  13  anormal\n",
      "[13, 'cclothes', 'eating', 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  14  anormal\n",
      "[14, 'cclothes', 'eating', 'toileting', 'whandface']\n",
      "Dia  15  anormal\n",
      "[15, 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  16  anormal\n",
      "[16, 'eating', 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  17  anormal\n",
      "[17, 'mcoffe', 'toileting']\n",
      "Dia  18  anormal\n",
      "[18, 'eating', 'mhotfood', 'whandface']\n",
      "Dia  19  anormal\n",
      "[19, 'cclothes', 'eating', 'mhotfood', 'whandface']\n",
      "Dia  20  anormal\n",
      "[20, 'cclothes', 'eating', 'mcoffe', 'toileting', 'whandface']\n",
      "Dia  21  anormal\n",
      "[21, 'whandface']\n",
      "Dia  22  anormal\n",
      "[22, 'cclothes', 'eating', 'mcoffe', 'mhotfood', 'toileting']\n",
      "Dia  23  anormal\n",
      "[23, 'eating', 'mcoffe', 'whandface']\n",
      "Dia  24  anormal\n",
      "[24, 'cclothes', 'eating', 'toileting', 'whandface']\n",
      "Dia  25  anormal\n",
      "[25, 'eating', 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  26  anormal\n",
      "[26, 'cclothes', 'eating', 'toileting', 'whandface']\n",
      "Dia  27  anormal\n",
      "[27, 'cclothes', 'eating', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  28  anormal\n",
      "[28, 'cclothes', 'eating', 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  29  anormal\n",
      "[29, 'cclothes', 'eating', 'mcoffe']\n",
      "Dia  30  normal\n",
      "Dia  31  anormal\n",
      "[31, 'eating', 'mcoffe', 'whandface']\n",
      "Dia  32  anormal\n",
      "[32, 'cclothes', 'eating', 'mcoffe', 'toileting']\n",
      "Dia  33  anormal\n",
      "[33, 'mhotfood']\n",
      "Dia  34  anormal\n",
      "[34, 'cclothes', 'eating', 'mcoffe', 'toileting', 'whandface']\n",
      "Dia  35  anormal\n",
      "[35, 'cclothes', 'eating']\n",
      "Dia  36  anormal\n",
      "[36, 'eating', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  37  anormal\n",
      "[37, 'cclothes', 'eating', 'toileting', 'whandface']\n",
      "Dia  38  anormal\n",
      "[38, 'cclothes', 'eating', 'mcoffe', 'whandface']\n",
      "Dia  39  anormal\n",
      "[39, 'cclothes', 'eating', 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  40  anormal\n",
      "[40, 'cclothes', 'eating', 'mhotfood', 'whandface']\n",
      "Dia  41  anormal\n",
      "[41, 'cclothes', 'eating', 'mcoffe', 'mhotfood', 'toileting']\n",
      "Dia  42  anormal\n",
      "[42, 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  43  normal\n",
      "Dia  44  normal\n",
      "Dia  45  normal\n",
      "Dia  46  normal\n",
      "Dia  47  normal\n",
      "Dia  48  normal\n",
      "Dia  49  normal\n",
      "Dia  50  normal\n",
      "Dia  51  normal\n",
      "Dia  52  normal\n",
      "Dia  53  normal\n",
      "Dia  54  normal\n",
      "Dia  55  normal\n",
      "Dia  56  normal\n",
      "Dia  57  normal\n",
      "Dia  58  normal\n",
      "Dia  59  normal\n",
      "Dia  60  normal\n",
      "Dia  61  normal\n",
      "Dia  62  normal\n",
      "Dia  63  normal\n",
      "Dia  64  normal\n",
      "Dia  65  normal\n",
      "Dia  66  normal\n",
      "Dia  67  normal\n",
      "Dia  68  normal\n",
      "Dia  69  normal\n",
      "Dia  70  normal\n",
      "Dia  71  normal\n",
      "Dia  72  normal\n",
      "Dia  73  normal\n",
      "Dia  74  normal\n",
      "Dia  75  normal\n",
      "Dia  76  normal\n",
      "Dia  77  normal\n",
      "Dia  78  normal\n",
      "Dia  79  normal\n",
      "Dia  80  normal\n",
      "Dia  81  normal\n",
      "Dia  82  normal\n",
      "Dia  83  normal\n",
      "Dia  84  normal\n"
     ]
    }
   ],
   "source": [
    "#inicio da detecção de anomalias\n",
    "dia = 0 #dia avaliado dia+1\n",
    "for x in dia_teste_s: #iteração entre os dias a serem analisados\n",
    "\n",
    "    amostra_dia = ([x]) #seleciona dodos do dia\n",
    "    pred_dia = lof_dia.predict(amostra_dia) #efetua a predição do dia\n",
    "    \n",
    "    if (pred_dia == -1): #dia classificado como anormal\n",
    "\n",
    "        print('Dia ',dia+1,' anormal')\n",
    "        lista_ativ = ['cclothes','eating','mcoffe','mhotfood','toileting',\n",
    "                      'whandface'] #lista de atividades a serem avaliadas\n",
    "\n",
    "        ativ_anomalas = [] #lista temporaria para armazenar atividades anormais\n",
    "        ativ_anomalas.append(dia+1) #add lista dia da atividade anomala\n",
    "        for atividade in lista_ativ: #percorrendo as atividades\n",
    "            \n",
    "            if (atividade == 'cclothes'): #avaliando atividade cclothes\n",
    "                amostra_ativ = cclothes_teste_s[dia] #amostra a ser classificada\n",
    "                amostra_ativ = ([amostra_ativ]) #formatando para array 2D\n",
    "                pred_ativ = rce_cclothes.predict(amostra_ativ) #efetuando a predição\n",
    "                if (pred_ativ == -1): #atividade predita como anormal\n",
    "                    ativ_anomalas.append('cclothes') #adicionando atividade as anormais\n",
    "                                                     # para o dia\n",
    "                        \n",
    "            if (atividade == 'eating'): #avaliando atividade eating\n",
    "                amostra_ativ = eating_teste_s[dia]\n",
    "                amostra_ativ = ([amostra_ativ])\n",
    "                pred_ativ = rce_eating.predict(amostra_ativ)\n",
    "                if (pred_ativ == -1):\n",
    "                    ativ_anomalas.append('eating')\n",
    "                    \n",
    "            if (atividade == 'mcoffe'): #avaliando atividade mcoffe\n",
    "                amostra_ativ = mcoffe_teste_s[dia]\n",
    "                amostra_ativ = ([amostra_ativ])\n",
    "                pred_ativ = rce_mcoffe.predict(amostra_ativ)\n",
    "                if (pred_ativ == -1):\n",
    "                    ativ_anomalas.append('mcoffe')\n",
    "                   \n",
    "            if (atividade == 'mhotfood'): #avaliando atividade mhotfood\n",
    "                amostra_ativ = mhotfood_teste_s[dia]\n",
    "                amostra_ativ = ([amostra_ativ])\n",
    "                pred_ativ = rce_mhotfood.predict(amostra_ativ)\n",
    "                if (pred_ativ == -1):\n",
    "                    ativ_anomalas.append('mhotfood')\n",
    "                    \n",
    "            if (atividade == 'toileting'): #avaliando atividade toileting\n",
    "                amostra_ativ = toileting_teste_s[dia]\n",
    "                amostra_ativ = ([amostra_ativ])\n",
    "                pred_ativ = rce_toileting.predict(amostra_ativ)\n",
    "                if (pred_ativ == -1):\n",
    "                    ativ_anomalas.append('toileting')\n",
    "                    \n",
    "            if (atividade == 'whandface'): #avaliando atividade whandface\n",
    "                amostra_ativ = whandface_teste_s[dia]\n",
    "                amostra_ativ = ([amostra_ativ])\n",
    "                pred_ativ = rce_whandface.predict(amostra_ativ)\n",
    "                if (pred_ativ == -1):\n",
    "                    ativ_anomalas.append('whandface')\n",
    "                    \n",
    "        #apresentando atividades anormais para o dia\n",
    "        print(ativ_anomalas)\n",
    "        \n",
    "    else: #dia classificado como normal\n",
    "        print('Dia ',dia+1,' normal')\n",
    "    dia = dia + 1 #incrementando o dia\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a52493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "095f6315",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dia  1  anormal\n",
      "[1, 'eating', 'mhotfood', 'toileting']\n",
      "Dia  2  anormal\n",
      "[2, 'toileting', 'whandface']\n",
      "Dia  3  anormal\n",
      "[3, 'whandface']\n",
      "Dia  4  anormal\n",
      "[4, 'eating', 'mcoffe', 'mhotfood', 'whandface']\n",
      "Dia  5  anormal\n",
      "[5, 'cclothes', 'eating']\n",
      "Dia  6  anormal\n",
      "[6, 'cclothes', 'eating', 'toileting']\n",
      "Dia  7  anormal\n",
      "[7, 'cclothes', 'mhotfood']\n",
      "Dia  8  anormal\n",
      "[8, 'cclothes', 'eating', 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  9  anormal\n",
      "[9, 'eating', 'mcoffe', 'toileting']\n",
      "Dia  10  anormal\n",
      "[10, 'cclothes', 'mhotfood', 'toileting']\n",
      "Dia  11  anormal\n",
      "[11, 'eating', 'mhotfood']\n",
      "Dia  12  anormal\n",
      "[12, 'cclothes', 'eating', 'mhotfood', 'whandface']\n",
      "Dia  13  anormal\n",
      "[13, 'cclothes', 'eating', 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  14  anormal\n",
      "[14, 'cclothes', 'eating', 'toileting', 'whandface']\n",
      "Dia  15  anormal\n",
      "[15, 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  16  anormal\n",
      "[16, 'eating', 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  17  anormal\n",
      "[17, 'mcoffe', 'toileting']\n",
      "Dia  18  anormal\n",
      "[18, 'eating', 'mhotfood', 'whandface']\n",
      "Dia  19  anormal\n",
      "[19, 'cclothes', 'eating', 'mhotfood', 'whandface']\n",
      "Dia  20  anormal\n",
      "[20, 'cclothes', 'eating', 'mcoffe', 'toileting', 'whandface']\n",
      "Dia  21  anormal\n",
      "[21, 'whandface']\n",
      "Dia  22  anormal\n",
      "[22, 'cclothes', 'eating', 'mcoffe', 'mhotfood', 'toileting']\n",
      "Dia  23  anormal\n",
      "[23, 'eating', 'mcoffe', 'whandface']\n",
      "Dia  24  anormal\n",
      "[24, 'cclothes', 'eating', 'toileting', 'whandface']\n",
      "Dia  25  anormal\n",
      "[25, 'eating', 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  26  anormal\n",
      "[26, 'cclothes', 'eating', 'toileting', 'whandface']\n",
      "Dia  27  anormal\n",
      "[27, 'cclothes', 'eating', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  28  anormal\n",
      "[28, 'cclothes', 'eating', 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  29  anormal\n",
      "[29, 'cclothes', 'eating', 'mcoffe']\n",
      "Dia  30  normal\n",
      "Dia  31  anormal\n",
      "[31, 'eating', 'mcoffe', 'whandface']\n",
      "Dia  32  anormal\n",
      "[32, 'cclothes', 'eating', 'mcoffe', 'toileting']\n",
      "Dia  33  anormal\n",
      "[33, 'mhotfood']\n",
      "Dia  34  anormal\n",
      "[34, 'cclothes', 'eating', 'mcoffe', 'toileting', 'whandface']\n",
      "Dia  35  anormal\n",
      "[35, 'cclothes', 'eating']\n",
      "Dia  36  anormal\n",
      "[36, 'eating', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  37  anormal\n",
      "[37, 'cclothes', 'eating', 'toileting', 'whandface']\n",
      "Dia  38  anormal\n",
      "[38, 'cclothes', 'eating', 'mcoffe', 'whandface']\n",
      "Dia  39  anormal\n",
      "[39, 'cclothes', 'eating', 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  40  anormal\n",
      "[40, 'cclothes', 'eating', 'mhotfood', 'whandface']\n",
      "Dia  41  anormal\n",
      "[41, 'cclothes', 'eating', 'mcoffe', 'mhotfood', 'toileting']\n",
      "Dia  42  anormal\n",
      "[42, 'mcoffe', 'mhotfood', 'toileting', 'whandface']\n",
      "Dia  43  normal\n",
      "Dia  44  normal\n",
      "Dia  45  normal\n",
      "Dia  46  normal\n",
      "Dia  47  normal\n",
      "Dia  48  normal\n",
      "Dia  49  normal\n",
      "Dia  50  normal\n",
      "Dia  51  normal\n",
      "Dia  52  normal\n",
      "Dia  53  normal\n",
      "Dia  54  normal\n",
      "Dia  55  normal\n",
      "Dia  56  normal\n",
      "Dia  57  normal\n",
      "Dia  58  normal\n",
      "Dia  59  normal\n",
      "Dia  60  normal\n",
      "Dia  61  normal\n",
      "Dia  62  normal\n",
      "Dia  63  normal\n",
      "Dia  64  normal\n",
      "Dia  65  normal\n",
      "Dia  66  normal\n",
      "Dia  67  normal\n",
      "Dia  68  normal\n",
      "Dia  69  normal\n",
      "Dia  70  normal\n",
      "Dia  71  normal\n",
      "Dia  72  normal\n",
      "Dia  73  normal\n",
      "Dia  74  normal\n",
      "Dia  75  normal\n",
      "Dia  76  normal\n",
      "Dia  77  normal\n",
      "Dia  78  normal\n",
      "Dia  79  normal\n",
      "Dia  80  normal\n",
      "Dia  81  normal\n",
      "Dia  82  normal\n",
      "Dia  83  normal\n",
      "Dia  84  normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, -1, 1, -1, 1, -1, -1, 1],\n",
       " [2, -1, 1, 1, 1, 1, -1, -1],\n",
       " [3, -1, 1, 1, 1, 1, 1, -1],\n",
       " [4, -1, 1, -1, -1, -1, 1, -1],\n",
       " [5, -1, -1, -1, 1, 1, 1, 1],\n",
       " [6, -1, -1, -1, 1, 1, -1, 1],\n",
       " [7, -1, -1, 1, 1, -1, 1, 1],\n",
       " [8, -1, -1, -1, -1, -1, -1, -1],\n",
       " [9, -1, 1, -1, -1, 1, -1, 1],\n",
       " [10, -1, -1, 1, 1, -1, -1, 1],\n",
       " [11, -1, 1, -1, 1, -1, 1, 1],\n",
       " [12, -1, -1, -1, 1, -1, 1, -1],\n",
       " [13, -1, -1, -1, -1, -1, -1, -1],\n",
       " [14, -1, -1, -1, 1, 1, -1, -1],\n",
       " [15, -1, 1, 1, 1, -1, -1, -1],\n",
       " [16, -1, 1, -1, -1, -1, -1, -1],\n",
       " [17, -1, 1, 1, -1, 1, -1, 1],\n",
       " [18, -1, 1, -1, 1, -1, 1, -1],\n",
       " [19, -1, -1, -1, 1, -1, 1, -1],\n",
       " [20, -1, -1, -1, -1, 1, -1, -1],\n",
       " [21, -1, 1, 1, 1, 1, 1, -1],\n",
       " [22, -1, -1, -1, -1, -1, -1, 1],\n",
       " [23, -1, 1, -1, -1, 1, 1, -1],\n",
       " [24, -1, -1, -1, 1, 1, -1, -1],\n",
       " [25, -1, 1, -1, -1, -1, -1, -1],\n",
       " [26, -1, -1, -1, 1, 1, -1, -1],\n",
       " [27, -1, -1, -1, 1, -1, -1, -1],\n",
       " [28, -1, -1, -1, -1, -1, -1, -1],\n",
       " [29, -1, -1, -1, -1, 1, 1, 1],\n",
       " [30, 1, 1, 1, 1, 1, 1, 1],\n",
       " [31, -1, 1, -1, -1, 1, 1, -1],\n",
       " [32, -1, -1, -1, -1, 1, -1, 1],\n",
       " [33, -1, 1, 1, 1, -1, 1, 1],\n",
       " [34, -1, -1, -1, -1, 1, -1, -1],\n",
       " [35, -1, -1, -1, 1, 1, 1, 1],\n",
       " [36, -1, 1, -1, 1, -1, -1, -1],\n",
       " [37, -1, -1, -1, 1, 1, -1, -1],\n",
       " [38, -1, -1, -1, -1, 1, 1, -1],\n",
       " [39, -1, -1, -1, -1, -1, -1, -1],\n",
       " [40, -1, -1, -1, 1, -1, 1, -1],\n",
       " [41, -1, -1, -1, -1, -1, -1, 1],\n",
       " [42, -1, 1, 1, -1, -1, -1, -1],\n",
       " [43, 1, 1, 1, 1, 1, 1, 1],\n",
       " [44, 1, 1, 1, 1, 1, 1, 1],\n",
       " [45, 1, 1, 1, 1, 1, 1, 1],\n",
       " [46, 1, 1, 1, 1, 1, 1, 1],\n",
       " [47, 1, 1, 1, 1, 1, 1, 1],\n",
       " [48, 1, 1, 1, 1, 1, 1, 1],\n",
       " [49, 1, 1, 1, 1, 1, 1, 1],\n",
       " [50, 1, 1, 1, 1, 1, 1, 1],\n",
       " [51, 1, 1, 1, 1, 1, 1, 1],\n",
       " [52, 1, 1, 1, 1, 1, 1, 1],\n",
       " [53, 1, 1, 1, 1, 1, 1, 1],\n",
       " [54, 1, 1, 1, 1, 1, 1, 1],\n",
       " [55, 1, 1, 1, 1, 1, 1, 1],\n",
       " [56, 1, 1, 1, 1, 1, 1, 1],\n",
       " [57, 1, 1, 1, 1, 1, 1, 1],\n",
       " [58, 1, 1, 1, 1, 1, 1, 1],\n",
       " [59, 1, 1, 1, 1, 1, 1, 1],\n",
       " [60, 1, 1, 1, 1, 1, 1, 1],\n",
       " [61, 1, 1, 1, 1, 1, 1, 1],\n",
       " [62, 1, 1, 1, 1, 1, 1, 1],\n",
       " [63, 1, 1, 1, 1, 1, 1, 1],\n",
       " [64, 1, 1, 1, 1, 1, 1, 1],\n",
       " [65, 1, 1, 1, 1, 1, 1, 1],\n",
       " [66, 1, 1, 1, 1, 1, 1, 1],\n",
       " [67, 1, 1, 1, 1, 1, 1, 1],\n",
       " [68, 1, 1, 1, 1, 1, 1, 1],\n",
       " [69, 1, 1, 1, 1, 1, 1, 1],\n",
       " [70, 1, 1, 1, 1, 1, 1, 1],\n",
       " [71, 1, 1, 1, 1, 1, 1, 1],\n",
       " [72, 1, 1, 1, 1, 1, 1, 1],\n",
       " [73, 1, 1, 1, 1, 1, 1, 1],\n",
       " [74, 1, 1, 1, 1, 1, 1, 1],\n",
       " [75, 1, 1, 1, 1, 1, 1, 1],\n",
       " [76, 1, 1, 1, 1, 1, 1, 1],\n",
       " [77, 1, 1, 1, 1, 1, 1, 1],\n",
       " [78, 1, 1, 1, 1, 1, 1, 1],\n",
       " [79, 1, 1, 1, 1, 1, 1, 1],\n",
       " [80, 1, 1, 1, 1, 1, 1, 1],\n",
       " [81, 1, 1, 1, 1, 1, 1, 1],\n",
       " [82, 1, 1, 1, 1, 1, 1, 1],\n",
       " [83, 1, 1, 1, 1, 1, 1, 1],\n",
       " [84, 1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lista predições para o periodo de dias avaliados\n",
    "lista_predicoes = []\n",
    "dia = 0 #dia avaliado dia+1\n",
    "\n",
    "for x in dia_teste_s: #iteração entre os dias a serem analisados\n",
    "\n",
    "    amostra_dia = ([x]) #seleciona dodos do dia\n",
    "    pred_dia = lof_dia.predict(amostra_dia) #efetua a predição do dia\n",
    "    \n",
    "    if (pred_dia == -1): #dia classificado como anormal\n",
    "        predicoes = [] ##predicoes para posterior análise\n",
    "\n",
    "        predicoes.append(dia+1) ##predicoes para posterior análise\n",
    "        predicoes.append(pred_dia[0]) ##predicoes para posterior análise\n",
    "        \n",
    "        print('Dia ',dia+1,' anormal')\n",
    "        lista_ativ = ['cclothes','eating','mcoffe','mhotfood','toileting',\n",
    "                      'whandface'] #lista de atividades a serem avaliadas\n",
    "\n",
    "        ativ_anomalas = [] #lista temporaria para armazenar atividades anormais\n",
    "        ativ_anomalas.append(dia+1) #add lista dia da atividade anomala\n",
    "        for atividade in lista_ativ: #percorrendo as atividades\n",
    "            \n",
    "            if (atividade == 'cclothes'): #avaliando atividade cclothes\n",
    "                amostra_ativ = cclothes_teste_s[dia] #amostra a ser classificada\n",
    "                amostra_ativ = ([amostra_ativ]) #formatando para array 2D\n",
    "                pred_ativ = rce_cclothes.predict(amostra_ativ) #efetuando a predição\n",
    "                predicoes.append(pred_ativ[0]) ##predicoes para posterior análise\n",
    "                if (pred_ativ == -1): #atividade predita como anormal\n",
    "                    ativ_anomalas.append('cclothes') #adicionando atividade as anormais\n",
    "                                                     # para o dia\n",
    "                        \n",
    "            if (atividade == 'eating'): #avaliando atividade eating\n",
    "                amostra_ativ = eating_teste_s[dia]\n",
    "                amostra_ativ = ([amostra_ativ])\n",
    "                pred_ativ = rce_eating.predict(amostra_ativ)\n",
    "                predicoes.append(pred_ativ[0]) ##predicoes para posterior análise               \n",
    "                if (pred_ativ == -1):\n",
    "                    ativ_anomalas.append('eating')\n",
    "                    \n",
    "            if (atividade == 'mcoffe'): #avaliando atividade mcoffe\n",
    "                amostra_ativ = mcoffe_teste_s[dia]\n",
    "                amostra_ativ = ([amostra_ativ])\n",
    "                pred_ativ = rce_mcoffe.predict(amostra_ativ)\n",
    "                predicoes.append(pred_ativ[0]) ##predicoes para posterior análise           \n",
    "                if (pred_ativ == -1):\n",
    "                    ativ_anomalas.append('mcoffe')\n",
    "                   \n",
    "            if (atividade == 'mhotfood'): #avaliando atividade mhotfood\n",
    "                amostra_ativ = mhotfood_teste_s[dia]\n",
    "                amostra_ativ = ([amostra_ativ])\n",
    "                pred_ativ = rce_mhotfood.predict(amostra_ativ)\n",
    "                predicoes.append(pred_ativ[0]) ##predicoes para posterior análise\n",
    "                if (pred_ativ == -1):\n",
    "                    ativ_anomalas.append('mhotfood')\n",
    "                    \n",
    "            if (atividade == 'toileting'): #avaliando atividade toileting\n",
    "                amostra_ativ = toileting_teste_s[dia]\n",
    "                amostra_ativ = ([amostra_ativ])\n",
    "                pred_ativ = rce_toileting.predict(amostra_ativ)\n",
    "                predicoes.append(pred_ativ[0]) ##predicoes para posterior análise              \n",
    "                if (pred_ativ == -1):\n",
    "                    ativ_anomalas.append('toileting')\n",
    "                    \n",
    "            if (atividade == 'whandface'): #avaliando atividade whandface\n",
    "                amostra_ativ = whandface_teste_s[dia]\n",
    "                amostra_ativ = ([amostra_ativ])\n",
    "                pred_ativ = rce_whandface.predict(amostra_ativ)\n",
    "                predicoes.append(pred_ativ[0]) ##predicoes para posterior análise         \n",
    "                if (pred_ativ == -1):\n",
    "                    ativ_anomalas.append('whandface')\n",
    "                    \n",
    "        #apresentando atividades anormais para o dia\n",
    "        print(ativ_anomalas)\n",
    "        lista_predicoes.append(predicoes) ##predicoes para posterior análise        \n",
    "        \n",
    "    else: #dia classificado como normal\n",
    "        print('Dia ',dia+1,' normal')\n",
    "        lista_predicoes.append([dia+1,1,1,1,1,1,1,1]) ##predicoes para posterior análise\n",
    "    dia = dia + 1 #incrementando o dia\n",
    "\n",
    "lista_predicoes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb79b047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e787553f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
